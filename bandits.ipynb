{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandits:\n",
    "    def __init__(self, n_arms, n_trials):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def generate_bandits(self):\n",
    "        \"\"\"A function to generate the bandits with random quality and variance\"\"\"\n",
    "        self.Bandit_quality = np.random.randint(0, 10, self.n_arms).reshape(self.n_arms, 1)\n",
    "        self.Bandit_variance = np.random.randint(low=1, high=3, size=self.n_arms).reshape(self.n_arms, 1)\n",
    "    \n",
    "    def generate_rewards(self):\n",
    "        \"\"\"A function to generate the rewards for the bandits\"\"\"\n",
    "        self.generate_bandits()\n",
    "        self.rewards_over_time = np.random.normal(self.Bandit_quality, self.Bandit_variance, (self.n_arms, self.n_trials))\n",
    "        return self.rewards_over_time\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: 5866.163543882582\n"
     ]
    }
   ],
   "source": [
    "class EpsilonGreedy:\n",
    "    \"\"\" An epsilon-greedy agent from www.geeksforgeeks.org\"\"\"\n",
    "    def __init__(self, n_arms, epsilon):\n",
    "        self.n_arms = n_arms\n",
    "        self.epsilon = epsilon\n",
    "        self.counts = np.zeros(n_arms)  # Number of times each arm is pulled\n",
    "        self.values = np.zeros(n_arms)  # Estimated values of each arm\n",
    "\n",
    "    def select_arm(self):\n",
    "        \"\"\" Select the arm with the highest estimated value with probability 1 - epsilon\"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, self.n_arms)\n",
    "        else:\n",
    "            return np.argmax(self.values)\n",
    "\n",
    "    def update(self, chosen_arm, reward):\n",
    "        \"\"\" Update the estimated value of the chosen arm \"\"\"\n",
    "        self.counts[chosen_arm] += 1\n",
    "        n = self.counts[chosen_arm]\n",
    "        value = self.values[chosen_arm]\n",
    "        self.values[chosen_arm] = ((n - 1) / n) * value + (1 / n) * reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB:\n",
    "    def __init__(self, n_arms, epsilon):\n",
    "        self.n_arms = n_arms\n",
    "        self.epsilon = epsilon\n",
    "        self.counts = np.zeros(n_arms)  # Number of times each arm is pulled\n",
    "        self.values = np.zeros(n_arms)  # Estimated values of each arm\n",
    "        self.upper_bounds = np.zeros(n_arms)\n",
    "\n",
    "    def select_arm(self):\n",
    "        total_counts = np.sum(self.counts)\n",
    "        \n",
    "        if total_counts < self.n_arms:\n",
    "            # Select each arm at least once\n",
    "            return int(total_counts)\n",
    "        \n",
    "        # Otherwise, calculate UCB for each arm\n",
    "        r = self.values / self.counts\n",
    "        delta = np.sqrt((2 * np.log(total_counts)) / self.counts)\n",
    "        self.upper_bounds = r + delta\n",
    "\n",
    "        # Select the arm with the highest upper confidence bound\n",
    "        return np.argmax(self.upper_bounds)\n",
    "\n",
    "    def update(self, chosen_arm, reward):\n",
    "        \"\"\" Update the estimated value of the chosen arm \"\"\"\n",
    "        self.counts[chosen_arm] += 1\n",
    "        n = self.counts[chosen_arm]\n",
    "        value = self.values[chosen_arm]\n",
    "        self.values[chosen_arm] = ((n - 1) / n) * value + (1 / n) * reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "n_arms = 5\n",
    "epsilon = 0.1\n",
    "n_trials = 1000\n",
    "\n",
    "Bandit = Bandits(n_arms, n_trials)\n",
    "rewards_over_time = Bandit.generate_rewards()\n",
    "\n",
    "agent = EpsilonGreedy(n_arms, epsilon)\n",
    "total_reward = 0\n",
    "\n",
    "for t in range(n_trials):\n",
    "    arm = agent.select_arm()\n",
    "    reward = rewards_over_time[arm, t]\n",
    "    agent.update(arm, reward)\n",
    "    total_reward += reward\n",
    "\n",
    "print(\"Total Reward:\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: 4020.2621764256915\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "n_arms = 5\n",
    "epsilon = 0.1\n",
    "n_trials = 1000\n",
    "\n",
    "Bandit = Bandits(n_arms, n_trials)\n",
    "rewards_over_time = Bandit.generate_rewards()\n",
    "\n",
    "agent = UCB(n_arms, epsilon)\n",
    "total_reward = 0\n",
    "UCB_rewards = []\n",
    "for t in range(n_trials):\n",
    "    arm = agent.select_arm()\n",
    "    reward = rewards_over_time[arm, t]\n",
    "    agent.update(arm, reward)\n",
    "    total_reward += reward\n",
    "    UCB_rewards.append(total_reward)\n",
    "\n",
    "print(\"Total Reward:\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
